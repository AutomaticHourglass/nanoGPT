/Users/unsalgokdag/git/professional/nanoRWKV/model.py:91: UserWarning:
################################################################################
                                      Note
The GPT-mode forward() should only be called when we are training models.
Now we are using it for inference for simplicity, which works, but will be very inefficient.
################################################################################
  warnings.warn(f'\n{"#"*80}\n\n{" "*38}Note\nThe GPT-mode forward() should only be called when we are training models.\nNow we are using it for inference for simplicity, which works, but will be very inefficient.\n\n{"#"*80}\n')
step 0, tokens 0: train loss 3.8147, val loss 3.8155 avg perplexity: 5.3266
iter 0: loss 3.8246, time 5458.63ms, mfu -100.00%
/Users/unsalgokdag/git/professional/nanoRWKV/model.py:91: UserWarning:
################################################################################
                                      Note
The GPT-mode forward() should only be called when we are training models.
Now we are using it for inference for simplicity, which works, but will be very inefficient.
################################################################################
  warnings.warn(f'\n{"#"*80}\n\n{" "*38}Note\nThe GPT-mode forward() should only be called when we are training models.\nNow we are using it for inference for simplicity, which works, but will be very inefficient.\n\n{"#"*80}\n')
iter 25: loss 2.4127, time 1832.40ms, mfu 0.06%
